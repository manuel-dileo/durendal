{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f83710b",
   "metadata": {},
   "source": [
    "Notebook to reproduce the results for multirelational future link prediction experiments. Note that the code to run the experiments is the same for all the datasets and you need to select on which dataset you want to run the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bc98a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, GRUCell\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score\n",
    "\n",
    "import random\n",
    "\n",
    "import bisect\n",
    "\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.utils import negative_sampling, structured_negative_sampling\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.transforms import RandomLinkSplit,NormalizeFeatures,Constant,OneHotDegree\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import GCNConv,SAGEConv,GATv2Conv, GINConv, Linear, GCN, GAT\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28a959a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multirelational import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee235ca9",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd99646",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots = get_icews_dataset()\n",
    "#snapshots = get_gdelt_dataset() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be230e52",
   "metadata": {},
   "source": [
    "# TRAINING AND EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf53e19c",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812c35ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_insort(a, x, lo=0, hi=None):\n",
    "    \"\"\"Insert item x in list a, and keep it reverse-sorted assuming a\n",
    "    is reverse-sorted.\n",
    "\n",
    "    If x is already in a, insert it to the right of the rightmost x.\n",
    "\n",
    "    Optional args lo (default 0) and hi (default len(a)) bound the\n",
    "    slice of a to be searched.\n",
    "    \n",
    "    Function useful to compute MRR.\n",
    "    \"\"\"\n",
    "    if lo < 0:\n",
    "        raise ValueError('lo must be non-negative')\n",
    "    if hi is None:\n",
    "        hi = len(a)\n",
    "    while lo < hi:\n",
    "        mid = (lo+hi)//2\n",
    "        if x > a[mid]: hi = mid\n",
    "        else: lo = mid+1\n",
    "    a.insert(lo, x)\n",
    "    return lo\n",
    "\n",
    "def compute_mrr(real_scores, fake_scores):\n",
    "    srr = 0\n",
    "    count = 0\n",
    "    for i,score in enumerate(real_scores):\n",
    "        try:\n",
    "            fake_scores_cp = copy.copy([fake_scores[i]])\n",
    "        except IndexError: break\n",
    "        rank = reverse_insort(fake_scores_cp, score)\n",
    "        rr = 1/(rank+1) #index starts from zero\n",
    "        srr+=rr\n",
    "        count+=1\n",
    "    return srr/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fff3eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(snapshots, hidden_conv_1, hidden_conv_2, rnn_size=500, device='cpu'):\n",
    "    num_snap = len(snapshots)\n",
    "    hetdata = copy.deepcopy(snapshots[0])\n",
    "    edge_types = list(hetdata.edge_index_dict.keys())\n",
    "    \n",
    "    lr = 0.001\n",
    "    weight_decay = 5e-3\n",
    "    \n",
    "    in_channels = {node: len(v[0]) for node,v in hetdata.x_dict.items()}\n",
    "    num_nodes = {node: len(v) for node, v in hetdata.x_dict.items()}\n",
    "    \n",
    "    homdata = copy.deepcopy(snapshots[0]).to_homogeneous()\n",
    "    in_channels_homo = homdata.x.size(1)\n",
    "    num_nodes_homo = homdata.x.size(0)\n",
    "    \n",
    "    #DURENDAL\n",
    "    durendal = RDurendal(in_channels, num_nodes, hetdata.metadata(),\n",
    "                        hidden_conv_1=hidden_conv_1,\n",
    "                        hidden_conv_2=hidden_conv_2)\n",
    "    \n",
    "    durendal.reset_parameters()\n",
    "    \n",
    "    durendalopt = torch.optim.Adam(params=durendal.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "    \n",
    "    #HAN\n",
    "    han = RHAN(in_channels, hidden_conv_1, hidden_conv_2, hetdata.metadata())\n",
    "    han.reset_parameters()\n",
    "    hanopt = torch.optim.Adam(params=han.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "    \n",
    "    #HetEvolveGCN\n",
    "    hev = RHEGCN(in_channels_homo, num_nodes_homo, list(hetdata.edge_index_dict.keys()))\n",
    "    hev.reset_parameters()\n",
    "    hevopt = torch.optim.Adam(params=hev.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "    \n",
    "    #ATU\n",
    "    atu = RATU(in_channels, num_nodes, hetdata.metadata(),\n",
    "                        hidden_conv_1=hidden_conv_1,\n",
    "                        hidden_conv_2=hidden_conv_2)\n",
    "    atu.reset_parameters()\n",
    "    atuopt = torch.optim.Adagrad(params=atu.parameters(), lr=1e-1, weight_decay = weight_decay)\n",
    "    \n",
    "    #ComplEx\n",
    "    cplex = ComplEx(2000, num_nodes_homo, hetdata.metadata())\n",
    "    cplexopt = torch.optim.Adam(params=cplex.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "    \n",
    "    #TNTComplEx\n",
    "    tnt = TNTComplEx(2000, num_nodes_homo, hetdata.metadata(), len(snapshots), rnn_size)\n",
    "    tntopt = torch.optim.Adam(params=tnt.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "    \n",
    "    past_dict_1 = {}\n",
    "    for node in hetdata.x_dict.keys():\n",
    "        past_dict_1[node] = {}\n",
    "    for src,r,dst in hetdata.edge_index_dict.keys():\n",
    "        past_dict_1[src][r] = torch.Tensor([[0 for j in range(hidden_conv_1)] for i in range(hetdata[src].num_nodes)])\n",
    "        past_dict_1[dst][r] = torch.Tensor([[0 for j in range(hidden_conv_1)] for i in range(hetdata[dst].num_nodes)])\n",
    "        \n",
    "    past_dict_2 = {}\n",
    "    for node in hetdata.x_dict.keys():\n",
    "        past_dict_2[node] = {}\n",
    "    for src,r,dst in hetdata.edge_index_dict.keys():\n",
    "        past_dict_2[src][r] = torch.Tensor([[0 for j in range(hidden_conv_2)] for i in range(hetdata[src].num_nodes)])\n",
    "        past_dict_2[dst][r] = torch.Tensor([[0 for j in range(hidden_conv_2)] for i in range(hetdata[dst].num_nodes)])\n",
    "    \n",
    "    past_dict_1_atu = copy.deepcopy(past_dict_1)\n",
    "    past_dict_2_atu = copy.deepcopy(past_dict_2)\n",
    "    \n",
    "    durendal_avgpr = 0\n",
    "    durendal_mrr = 0\n",
    "    han_avgpr = 0\n",
    "    han_mrr = 0\n",
    "    hev_avgpr = 0\n",
    "    hev_mrr = 0\n",
    "    atu_avgpr = 0\n",
    "    atu_mrr = 0\n",
    "    cplex_avgpr = 0\n",
    "    cplex_mrr = 0\n",
    "    tnt_avgpr = 0\n",
    "    tnt_mrr = 0\n",
    "    \n",
    "    for i in range(num_snap-1):\n",
    "        #CREATE TRAIN + VAL + TEST SET FOR THE CURRENT SNAP\n",
    "        snapshot = copy.deepcopy(snapshots[i])\n",
    "        \n",
    "        link_split = RandomLinkSplit(num_val=0.0, num_test=0.20, edge_types=edge_types)\n",
    "        \n",
    "        het_train_data, _, het_val_data = link_split(snapshot)\n",
    "     \n",
    "        het_test_data = copy.deepcopy(snapshots[i+1])\n",
    "        future_link_split = RandomLinkSplit(num_val=0, num_test=0, edge_types = edge_types) #useful only for negative sampling\n",
    "        het_test_data, _, _ = future_link_split(het_test_data)\n",
    "        \n",
    "        #TRAIN AND TEST THE MODEL FOR THE CURRENT SNAP\n",
    "        durendal, dur_avgpr_test, dur_mrr_test , past_dict_1, past_dict_2, durendalopt =\\\n",
    "            durendal_train_single_snapshot(durendal, snapshot, i, het_train_data, het_val_data, het_test_data,\\\n",
    "                                  past_dict_1, past_dict_2, durendalopt)\n",
    "        \n",
    "        han, han_avgpr_test, han_mrr_test, hanopt =\\\n",
    "            het_train_single_snapshot(han, snapshot, het_train_data, het_val_data, het_test_data, hanopt)\n",
    "            \n",
    "        hev, hev_avgpr_test, hev_mrr_test, hevopt =\\\n",
    "            het_train_single_snapshot(hev, snapshot, het_train_data, het_val_data, het_test_data, hevopt)\n",
    "        \n",
    "        atu, atu_avgpr_test, atu_mrr_test , past_dict_1_atu, past_dict_2_atu, atuopt =\\\n",
    "            durendal_train_single_snapshot(atu, snapshot, i, het_train_data, het_val_data, het_test_data,\\\n",
    "                                  past_dict_1_atu, past_dict_2_atu, atuopt)\n",
    "        \n",
    "        cplex, cplex_avgpr_test, cplex_mrr_test, cplexopt =\\\n",
    "            het_train_single_snapshot(cplex, snapshot, het_train_data, het_val_data, het_test_data, cplexopt)\n",
    "        \n",
    "        tnt, tnt_avgpr_test, tnt_mrr_test, tntopt =\\\n",
    "            tnt_train_single_snapshot(tnt, snapshot, i, het_train_data, het_val_data, het_test_data, tntopt)\n",
    "        \n",
    "        #SAVE AND DISPLAY EVALUATION\n",
    "        print(f'Snapshot: {i}\\n')\n",
    "        print(f' DURENDAL AVGPR Test: {dur_avgpr_test} \\n MRR Test: {dur_mrr_test}\\n')\n",
    "        print(f' HAN AVGPR Test: {han_avgpr_test} \\n MRR Test: {han_mrr_test}\\n')\n",
    "        print(f' HetEvolveGCN AVGPR Test: {hev_avgpr_test} \\n MRR Test: {hev_mrr_test}\\n')\n",
    "        print(f' ATU AVGPR Test: {atu_avgpr_test} \\n MRR Test: {atu_mrr_test}\\n')\n",
    "        print(f' ComplEx AVGPR Test: {cplex_avgpr_test} \\n MRR Test: {cplex_mrr_test}\\n')\n",
    "        print(f' TNTComplEx AVGPR Test: {tnt_avgpr_test} \\n MRR Test: {tnt_mrr_test}\\n')\n",
    "        durendal_avgpr += dur_avgpr_test\n",
    "        durendal_mrr += dur_mrr_test\n",
    "        han_avgpr += han_avgpr_test\n",
    "        han_mrr += han_mrr_test\n",
    "        hev_avgpr += hev_avgpr_test\n",
    "        hev_mrr += hev_mrr_test\n",
    "        atu_avgpr += atu_avgpr_test\n",
    "        atu_mrr += atu_mrr_test\n",
    "        cplex_avgpr += cplex_avgpr_test\n",
    "        cplex_mrr += cplex_mrr_test\n",
    "        tnt_avgpr += tnt_avgpr_test\n",
    "        tnt_mrr += tnt_mrr_test\n",
    "        \n",
    "        \n",
    "    durendal_avgpr_all = durendal_avgpr / (num_snap-1)\n",
    "    durendal_mrr_all = durendal_mrr / (num_snap-1)\n",
    "    han_avgpr_all = han_avgpr / (num_snap-1)\n",
    "    han_mrr_all = han_mrr / (num_snap-1)\n",
    "    hev_avgpr_all = hev_avgpr / (num_snap-1)\n",
    "    hev_mrr_all = hev_mrr / (num_snap-1)\n",
    "    atu_avgpr_all = atu_avgpr / (num_snap-1)\n",
    "    atu_mrr_all = atu_mrr / (num_snap-1)\n",
    "    cplex_avgpr_all = cplex_avgpr / (num_snap-1)\n",
    "    cplex_mrr_all = cplex_mrr / (num_snap-1)\n",
    "    tnt_avgpr_all = tnt_avgpr / (num_snap-1)\n",
    "    tnt_mrr_all = tnt_mrr / (num_snap-1)\n",
    "    \n",
    "    print('DURENDAL')\n",
    "    print(f'\\tAVGPR over time: Test: {durendal_avgpr_all}')\n",
    "    print(f'\\tMRR over time: Test: {durendal_mrr_all}')\n",
    "    print()\n",
    "    print('HAN')\n",
    "    print(f'\\tAVGPR over time: Test: {han_avgpr_all}')\n",
    "    print(f'\\tMRR over time: Test: {han_mrr_all}')\n",
    "    print()\n",
    "    print('HetEvolveGCN')\n",
    "    print(f'\\tAVGPR over time: Test: {hev_avgpr_all}')\n",
    "    print(f'\\tMRR over time: Test: {hev_mrr_all}')\n",
    "    print('ATU')\n",
    "    print(f'\\tAVGPR over time: Test: {atu_avgpr_all}')\n",
    "    print(f'\\tMRR over time: Test: {atu_mrr_all}')\n",
    "    print('ComplEx')\n",
    "    print(f'\\tAVGPR over time: Test: {cplex_avgpr_all}')\n",
    "    print(f'\\tMRR over time: Test: {cplex_mrr_all}')\n",
    "    print('TNTComplEx')\n",
    "    print(f'\\tAVGPR over time: Test: {tnt_avgpr_all}')\n",
    "    print(f'\\tMRR over time: Test: {tnt_mrr_all}')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2be8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def durendal_train_single_snapshot(model, data, i_snap, train_data, val_data, test_data,\\\n",
    "                          past_dict_1, past_dict_2,\\\n",
    "                          optimizer, device='cpu', num_epochs=50, verbose=False):\n",
    "    \n",
    "    mrr_val_max = 0\n",
    "    avgpr_val_max = 0\n",
    "    best_model = model\n",
    "    train_data = train_data.to(device)\n",
    "    best_epoch = -1\n",
    "    best_past_dict_1 = {}\n",
    "    best_past_dict_2 = {}\n",
    "    \n",
    "    tol = 5e-2\n",
    "    \n",
    "    edge_types = list(data.edge_index_dict.keys())\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        ## Note\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Compute loss and backpropagate\n",
    "        ## 3. Update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred_dict, past_dict_1, past_dict_2 =\\\n",
    "            model(train_data.x_dict, train_data.edge_index_dict, train_data,\\\n",
    "                  i_snap, past_dict_1, past_dict_2)\n",
    "        \n",
    "        preds = torch.Tensor()\n",
    "        edge_labels = torch.Tensor()\n",
    "        for edge_t in edge_types:\n",
    "            preds = torch.cat((preds,pred_dict[edge_t]),-1)\n",
    "            edge_labels = torch.cat((edge_labels,train_data[edge_t].edge_label.type_as(pred_dict[edge_t])),-1)\n",
    "            \n",
    "        #compute loss function based on all edge types\n",
    "        loss = model.loss(preds, edge_labels)\n",
    "        loss = torch.autograd.Variable(loss, requires_grad = True)\n",
    "        \n",
    "        loss.backward(retain_graph=True)  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        log = 'Epoch: {:03d}\\n AVGPR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n MRR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n F1-Score Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n Loss: {}'\n",
    "        avgpr_score_val, mrr_val = durendal_test(model, i_snap, val_data, data, device)\n",
    "        \n",
    "        \"\"\"\n",
    "        if mrr_val_max-tol < mrr_val:\n",
    "            mrr_val_max = mrr_val\n",
    "            best_epoch = epoch\n",
    "            best_current_embeddings = current_embeddings\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        #print(f'Epoch: {epoch} done')\n",
    "            \n",
    "        \"\"\"\n",
    "        if avgpr_val_max-tol <= avgpr_score_val:\n",
    "            avgpr_val_max = avgpr_score_val\n",
    "            best_epoch = epoch\n",
    "            best_past_dict_1 = past_dict_1\n",
    "            best_past_dict_2 = past_dict_2\n",
    "            best_model = model\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    avgpr_score_test, mrr_test = durendal_test(model, i_snap, test_data, data, device)\n",
    "            \n",
    "    if verbose:\n",
    "        print(f'Best Epoch: {best_epoch}')\n",
    "    #print(f'Best Epoch: {best_epoch}')\n",
    "    \n",
    "    return best_model, avgpr_score_test, mrr_test, best_past_dict_1, best_past_dict_2, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc165c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def het_train_single_snapshot(model, data, train_data, val_data, test_data,\\\n",
    "                          optimizer, device='cpu', num_epochs=50, verbose=False):\n",
    "    \n",
    "    mrr_val_max = 0\n",
    "    avgpr_val_max = 0\n",
    "    best_model = model\n",
    "    train_data = train_data.to(device)\n",
    "    best_epoch = -1\n",
    "    \n",
    "    tol = 5e-2\n",
    "    \n",
    "    edge_types = list(data.edge_index_dict.keys())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        ## Note\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Compute loss and backpropagate\n",
    "        ## 3. Update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        pred_dict =\\\n",
    "            model(train_data.x_dict, train_data.edge_index_dict, train_data)\n",
    "        \n",
    "        preds = torch.Tensor()\n",
    "        edge_labels = torch.Tensor()\n",
    "        for edge_t in edge_types:\n",
    "            preds = torch.cat((preds,pred_dict[edge_t]),-1)\n",
    "            edge_labels = torch.cat((edge_labels,train_data[edge_t].edge_label.type_as(pred_dict[edge_t])),-1)\n",
    "        \n",
    "        #compute loss function based on all edge types\n",
    "        loss = model.loss(preds, edge_labels)\n",
    "        loss = torch.autograd.Variable(loss, requires_grad = True)\n",
    "        \n",
    "        loss.backward(retain_graph=True)  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        log = 'Epoch: {:03d}\\n AVGPR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n MRR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n F1-Score Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n Loss: {}'\n",
    "        avgpr_score_val, mrr_val = het_test(model, val_data, data, device)\n",
    "        \n",
    "        \"\"\"\n",
    "        if mrr_val_max-tol < mrr_val:\n",
    "            mrr_val_max = mrr_val\n",
    "            best_epoch = epoch\n",
    "            best_current_embeddings = current_embeddings\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        #print(f'Epoch: {epoch} done')\n",
    "            \n",
    "        \"\"\"\n",
    "        if avgpr_val_max-tol <= avgpr_score_val:\n",
    "            avgpr_val_max = avgpr_score_val\n",
    "            best_epoch = epoch\n",
    "            best_model = model\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    avgpr_score_test, mrr_test = het_test(model, test_data, data, device)\n",
    "            \n",
    "    if verbose:\n",
    "        print(f'Best Epoch: {best_epoch}')\n",
    "    #print(f'Best Epoch: {best_epoch}')\n",
    "    \n",
    "    return best_model, avgpr_score_test, mrr_test, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7770f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnt_train_single_snapshot(model, data, isnap, train_data, val_data, test_data,\\\n",
    "                              optimizer, device='cpu', num_epochs=50, verbose=False):\n",
    "    \n",
    "    \n",
    "    mrr_val_max = 0\n",
    "    avgpr_val_max = 0\n",
    "    best_model = model\n",
    "    train_data = train_data.to(device)\n",
    "    best_epoch = -1\n",
    "    \n",
    "    tol = 5e-2\n",
    "    \n",
    "    edge_types = list(data.edge_index_dict.keys())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        ## Note\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Compute loss and backpropagate\n",
    "        ## 3. Update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        pred_dict =\\\n",
    "            model(train_data.x_dict, train_data.edge_index_dict, train_data, isnap)\n",
    "        \n",
    "        preds = torch.Tensor()\n",
    "        edge_labels = torch.Tensor()\n",
    "        for edge_t in edge_types:\n",
    "            preds = torch.cat((preds,pred_dict[edge_t]),-1)\n",
    "            edge_labels = torch.cat((edge_labels,train_data[edge_t].edge_label.type_as(pred_dict[edge_t])),-1)\n",
    "        \n",
    "        #compute loss function based on all edge types\n",
    "        loss = model.loss(preds, edge_labels)\n",
    "        loss = torch.autograd.Variable(loss, requires_grad = True)\n",
    "        \n",
    "        loss.backward(retain_graph=True)  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        log = 'Epoch: {:03d}\\n AVGPR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n MRR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n F1-Score Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n Loss: {}'\n",
    "        avgpr_score_val, mrr_val = tnt_test(model, isnap, val_data, data, device)\n",
    "        \n",
    "        \"\"\"\n",
    "        if mrr_val_max-tol < mrr_val:\n",
    "            mrr_val_max = mrr_val\n",
    "            best_epoch = epoch\n",
    "            best_current_embeddings = current_embeddings\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        #print(f'Epoch: {epoch} done')\n",
    "            \n",
    "        \"\"\"\n",
    "        if avgpr_val_max-tol <= avgpr_score_val:\n",
    "            avgpr_val_max = avgpr_score_val\n",
    "            best_epoch = epoch\n",
    "            best_model = model\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    avgpr_score_test, mrr_test = tnt_test(model, isnap, test_data, data, device)\n",
    "            \n",
    "    if verbose:\n",
    "        print(f'Best Epoch: {best_epoch}')\n",
    "    #print(f'Best Epoch: {best_epoch}')\n",
    "    \n",
    "    return best_model, avgpr_score_test, mrr_test, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df5e1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def durendal_test(model, i_snap, test_data, data, device='cpu'):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    test_data = test_data.to(device)\n",
    "    edge_types = list(data.edge_index_dict.keys())\n",
    "    \n",
    "\n",
    "    h_dict, *_ = model(test_data.x_dict, test_data.edge_index_dict, test_data, i_snap)\n",
    "    \n",
    "    tot_avgpr = 0\n",
    "    tot_mrr = 0\n",
    "    \n",
    "    num_rel = 0\n",
    "    \n",
    "    for edge_t in edge_types:\n",
    "        \n",
    "        h = h_dict[edge_t]\n",
    "        pred_cont = torch.sigmoid(h).cpu().detach().numpy()\n",
    "        \n",
    "        num_pos = (len(test_data[edge_t].edge_label_index[0])//2)\n",
    "        h_fake = h[num_pos:]\n",
    "        \n",
    "        fake_preds = torch.sigmoid(h_fake).cpu().detach().numpy()\n",
    "        edge_label = test_data[edge_t].edge_label.cpu().detach().numpy()\n",
    "      \n",
    "        if len(edge_label) >0:\n",
    "            avgpr_score = average_precision_score(edge_label, pred_cont)\n",
    "            mrr_score = compute_mrr(pred_cont[:num_pos], fake_preds)\n",
    "        \n",
    "            tot_avgpr += avgpr_score\n",
    "            tot_mrr += mrr_score\n",
    "            num_rel +=1\n",
    "\n",
    "    return tot_avgpr/num_rel, tot_mrr/num_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9efafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnt_test(model, isnap, test_data, data, device='cpu'):\n",
    "        \n",
    "    model.eval()\n",
    "\n",
    "    test_data = test_data.to(device)\n",
    "    \n",
    "    edge_types = list(data.edge_index_dict.keys())\n",
    "\n",
    "    h_dict = model(test_data.x_dict, test_data.edge_index_dict, test_data, isnap)\n",
    "    \n",
    "    tot_avgpr = 0\n",
    "    tot_mrr = 0\n",
    "    \n",
    "    num_rel = 0\n",
    "    \n",
    "    for edge_t in edge_types:\n",
    "        \n",
    "        h = h_dict[edge_t]\n",
    "        pred_cont = torch.sigmoid(h).cpu().detach().numpy()\n",
    "        \n",
    "        num_pos = (len(test_data[edge_t].edge_label_index[0])//2)\n",
    "        h_fake = h[num_pos:]\n",
    "        \n",
    "        fake_preds = torch.sigmoid(h_fake).cpu().detach().numpy()\n",
    "        edge_label = test_data[edge_t].edge_label.cpu().detach().numpy()\n",
    "      \n",
    "        if len(edge_label) >0:\n",
    "            avgpr_score = average_precision_score(edge_label, pred_cont)\n",
    "            mrr_score = compute_mrr(pred_cont[:num_pos], fake_preds)\n",
    "        \n",
    "            tot_avgpr += avgpr_score\n",
    "            tot_mrr += mrr_score\n",
    "            num_rel +=1\n",
    "\n",
    "    return tot_avgpr/num_rel, tot_mrr/num_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "769c8e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def het_test(model, test_data, data, device='cpu'):\n",
    "        \n",
    "    model.eval()\n",
    "\n",
    "    test_data = test_data.to(device)\n",
    "    \n",
    "    edge_types = list(data.edge_index_dict.keys())\n",
    "\n",
    "    h_dict = model(test_data.x_dict, test_data.edge_index_dict, test_data)\n",
    "    \n",
    "    tot_avgpr = 0\n",
    "    tot_mrr = 0\n",
    "    \n",
    "    num_rel = 0\n",
    "    \n",
    "    for edge_t in edge_types:\n",
    "        \n",
    "        h = h_dict[edge_t]\n",
    "        pred_cont = torch.sigmoid(h).cpu().detach().numpy()\n",
    "        \n",
    "        num_pos = (len(test_data[edge_t].edge_label_index[0])//2)\n",
    "        h_fake = h[num_pos:]\n",
    "        \n",
    "        fake_preds = torch.sigmoid(h_fake).cpu().detach().numpy()\n",
    "        edge_label = test_data[edge_t].edge_label.cpu().detach().numpy()\n",
    "      \n",
    "        if len(edge_label) >0:\n",
    "            avgpr_score = average_precision_score(edge_label, pred_cont)\n",
    "            mrr_score = compute_mrr(pred_cont[:num_pos], fake_preds)\n",
    "        \n",
    "            tot_avgpr += avgpr_score\n",
    "            tot_mrr += mrr_score\n",
    "            num_rel +=1\n",
    "\n",
    "    return tot_avgpr/num_rel, tot_mrr/num_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bee5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_conv_1=256\n",
    "hidden_conv_2=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24ef0f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rnn_size = 500\n",
    "seed = 12345\n",
    "device = torch.device('cuda')\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(12345)\n",
    "random.seed(12345)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1773a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "training(snapshots, hidden_conv_1, hidden_conv_2, rnn_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4310fc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot: 0\n",
      "\n",
      " DURENDAL AVGPR Test: 0.6945152819139191 \n",
      " MRR Test: 0.7484289489274509\n",
      "\n",
      " HAN AVGPR Test: 0.620657239790961 \n",
      " MRR Test: 0.701719840913266\n",
      "\n",
      " HetEvolveGCN AVGPR Test: 0.6849523169983367 \n",
      " MRR Test: 0.7299575377370908\n",
      "\n",
      " ATU AVGPR Test: 0.6615270644731575 \n",
      " MRR Test: 0.7213570597961507\n",
      "\n",
      " ComplEx AVGPR Test: 0.5522364373184646 \n",
      " MRR Test: 0.715243450883346\n",
      "\n",
      " TNTComplEx AVGPR Test: 0.5391827679585356 \n",
      " MRR Test: 0.7282787599428081\n",
      "\n",
      "Snapshot: 1\n",
      "\n",
      " DURENDAL AVGPR Test: 0.6261271198586591 \n",
      " MRR Test: 0.7333414239794852\n",
      "\n",
      " HAN AVGPR Test: 0.5777586217783623 \n",
      " MRR Test: 0.6869961236618269\n",
      "\n",
      " HetEvolveGCN AVGPR Test: 0.6566392174441823 \n",
      " MRR Test: 0.7128638126909104\n",
      "\n",
      " ATU AVGPR Test: 0.6568466772687545 \n",
      " MRR Test: 0.73555548192843\n",
      "\n",
      " ComplEx AVGPR Test: 0.500027539639371 \n",
      " MRR Test: 0.68497156338455\n",
      "\n",
      " TNTComplEx AVGPR Test: 0.5439902901738588 \n",
      " MRR Test: 0.7540950523057216\n",
      "\n",
      "Snapshot: 2\n",
      "\n",
      " DURENDAL AVGPR Test: 0.6632870948807704 \n",
      " MRR Test: 0.7479949325625519\n",
      "\n",
      " HAN AVGPR Test: 0.5843656505867673 \n",
      " MRR Test: 0.6935484539916963\n",
      "\n",
      " HetEvolveGCN AVGPR Test: 0.667084768999145 \n",
      " MRR Test: 0.7343275728207664\n",
      "\n",
      " ATU AVGPR Test: 0.6701351835924717 \n",
      " MRR Test: 0.7359367712499784\n",
      "\n",
      " ComplEx AVGPR Test: 0.5130971278427262 \n",
      " MRR Test: 0.7077701000411178\n",
      "\n",
      " TNTComplEx AVGPR Test: 0.5406865601739123 \n",
      " MRR Test: 0.746163131455317\n",
      "\n",
      "DURENDAL\n",
      "\tAVGPR over time: Test: 0.6613098322177828\n",
      "\tMRR over time: Test: 0.7432551018231627\n",
      "\n",
      "HAN\n",
      "\tAVGPR over time: Test: 0.5942605040520301\n",
      "\tMRR over time: Test: 0.6940881395222632\n",
      "\n",
      "HetEvolveGCN\n",
      "\tAVGPR over time: Test: 0.669558767813888\n",
      "\tMRR over time: Test: 0.7257163077495892\n",
      "ATU\n",
      "\tAVGPR over time: Test: 0.6628363084447946\n",
      "\tMRR over time: Test: 0.7309497709915197\n",
      "ComplEx\n",
      "\tAVGPR over time: Test: 0.5217870349335206\n",
      "\tMRR over time: Test: 0.7026617047696714\n",
      "TNTComplEx\n",
      "\tAVGPR over time: Test: 0.5412865394354355\n",
      "\tMRR over time: Test: 0.7428456479012823\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
